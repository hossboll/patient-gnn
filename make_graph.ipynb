{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import random\n",
    "import pickle as pkl\n",
    "import os\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating patient similarity graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity matrix, obtained from the similarity among patient feature vectors from medical codes, will be the basis for the creation of the patient similarity graph/GNN. \n",
    "In the end, we will add these embeddings as node feature vectors and reindex the graph to avoid bugs in the GNNs.  \n",
    "First, we will create a single graph for our transductive learning setting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading patient data\n",
    "path = r\"PATH/patient_emb_df.csv\"\n",
    "patient_data = pd.read_csv(path)\n",
    "\n",
    "patient_data = patient_data.drop(columns=['Unnamed: 0'])\n",
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.read_csv(r\"C:PATH/patient_emb_cols.csv\") \n",
    "embeddings_df = embeddings_df.drop(columns=['Unnamed: 0'])\n",
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = patient_data.join(embeddings_df)\n",
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = patient_data.drop(columns=[\"patient_embedding\"])\n",
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data.to_csv(r\"PATH/patient_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the patient similarity matrix\n",
    "Based on the cosine similarity among patient vectors, dim=300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_similarity_graph(k, sim_matrix, patient_df):\n",
    "    logging.info('Generating similarity graph...')\n",
    "    G_knn = nx.Graph()\n",
    "\n",
    "    # ensure the patient_df and sim_matrix are of the same length\n",
    "    assert len(patient_df) == len(sim_matrix), \"The patient df and similarity matrix must have the same number of rows.\"\n",
    "\n",
    "    patient_ids = patient_df['patient_id'].values\n",
    "    G_knn.add_nodes_from(patient_ids) # patients as nodes\n",
    "    \n",
    "    # top k most similar neighbors\n",
    "    for i, patient_i in tqdm(enumerate(patient_ids), total=len(patient_ids), desc='Generating graph'):\n",
    "        # get the indices of the top k most similar patients\n",
    "        # note: argsort()[-k-1:-1] could include the patient themself if they are in their own top k neighbors,\n",
    "        # so we need to check for self-loops when adding edges\n",
    "        patient_i_similarity = sim_matrix.iloc[i] # get patient i's row of similarity in the matrix\n",
    "        patient_i_similarity_asc = patient_i_similarity.argsort() # sort scores in ascending order\n",
    "        top_k_neighbors_indices = patient_i_similarity_asc[-k-1:-1][::-1] # select top k indices excluding patient\n",
    "        \n",
    "        # add edges between the patient and their top k neighbors\n",
    "        for j in top_k_neighbors_indices:\n",
    "            patient_j = patient_ids[j]\n",
    "            # check if patient_i and patient_j are not the same to avoid self-loops\n",
    "            if patient_i != patient_j:# and not G_knn.has_edge(patient_i, patient_j) and not G_knn.has_edge(patient_j, patient_i):\n",
    "                similarity = sim_matrix.iloc[i, j]\n",
    "                G_knn.add_edge(patient_i, patient_j, weight=similarity)\n",
    "\n",
    "    logging.info('Graph generation complete.')\n",
    "    return G_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix_cos = pd.read_csv(r\"PATH/cosine_sim_df.csv\").drop(columns=['Unnamed: 0']) \n",
    "similarity_matrix_cos = similarity_matrix_cos.clip(lower=0) # no need for negative sim\n",
    "similarity_matrix_cos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should get a square matrix, where the diagonal = 1 (patient is 100% similar to itself) and the rest are sim measurements\n",
    "similarity_matrix_cos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating similarity matrix\n",
    "similarity_matrix = similarity_matrix_cos.to_numpy()\n",
    "print(f\"Mean similarity: {np.nanmean(similarity_matrix)}\")\n",
    "print(f\"Median similarity: {np.nanmedian(similarity_matrix)}\")\n",
    "print(f\"Standard deviation: {np.nanstd(similarity_matrix)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate quartiles\n",
    "q1 = np.percentile(similarity_matrix, 25)\n",
    "q2 = np.percentile(similarity_matrix, 50) \n",
    "q3 = np.percentile(similarity_matrix, 75)\n",
    "q4 = np.max(similarity_matrix)\n",
    "\n",
    "print(f\"1st quartile: {q1}\")\n",
    "print(f\"2nd quartile (median): {q2}\")\n",
    "print(f\"3rd quartile: {q3}\")\n",
    "print(f\"4th quartile (max): {q4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of sim scores\n",
    "flattened = similarity_matrix.flatten()\n",
    "plt.hist(similarity_matrix.flatten(), bins=30, edgecolor='k', alpha=0.7)\n",
    "plt.title('Histogram of similarity scores')\n",
    "plt.xlabel('Similarity score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize scores between 0.75 and 0.9\n",
    "plt.hist(flattened, bins=30, range=(0.75, 0.9), edgecolor='k', alpha=0.7)\n",
    "plt.title('Similarity scores (0.75 to 0.9)')\n",
    "plt.xlabel('Similarity score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the similarity graph\n",
    "Now that we have our similarity data, let's generate the transductive training similarity graph.  \n",
    "We will use the calculated cosine similarity to measure how similar patients are, and the KNN algorithm to establish an edge between the top k most similar patients, given a patient. K will be decided with the elbow method.  \n",
    "The edges will be weighted by the similarity score (attention, not all GNN architectures use this information).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_elbow_curve(sim_matrix, max_k=10):\n",
    "    if isinstance(sim_matrix, pd.DataFrame):\n",
    "        sim_matrix = sim_matrix.values\n",
    "\n",
    "    distortions = []\n",
    "    for k in range(1, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=22, n_init='auto').fit(sim_matrix)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "\n",
    "    elbow_data = pd.DataFrame({\n",
    "        \"Number of clusters (K)\": range(1, max_k + 1),\n",
    "        \"Distortion\": distortions\n",
    "    })\n",
    "\n",
    "    fig = px.scatter(elbow_data,\n",
    "                     x=\"Number of clusters (K)\",\n",
    "                     y=\"Distortion\",\n",
    "                     title=\"Elbow plot: patient similarity graph\",\n",
    "                     labels={\n",
    "                         \"Number of clusters (K)\": \"Number of clusters (K)\",\n",
    "                         \"Distortion\": \"Distortion\"\n",
    "                     })\n",
    "\n",
    "    fig.update_traces(mode=\"lines+markers\", line=dict(color='#636EFA'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(tickmode=\"linear\", tick0=1, dtick=1),\n",
    "        width=900,\n",
    "        height=700,\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_elbow_curve(similarity_matrix_cos, max_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the graph with k = 3\n",
    "G_knn = generate_similarity_graph(3, similarity_matrix_cos, patient_data) #patient_data_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the generated graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of nodes: {G_knn.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G_knn.number_of_edges()}\")\n",
    "print(f\"Average degree: {sum(dict(G_knn.degree()).values()) / G_knn.number_of_nodes()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting ocurrence of degrees \n",
    "degree_sequence = sorted([d for n, d in G_knn.degree()], reverse=True)\n",
    "degree_count = Counter(degree_sequence)\n",
    "degree_df = pd.DataFrame(list(degree_count.items()), columns=['Degree', 'Count']).sort_values('Degree').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of node degrees\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(degree_df['Degree'], degree_df['Count'], color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of node degrees')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('No. of nodes')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_self_loops = len(list(nx.selfloop_edges(G_knn)))\n",
    "print(f\"self-loops in the graph: {num_self_loops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "# attention - run again after loading node features to see label colors\n",
    "def bfs_sample(graph, start_node, num_nodes):\n",
    "    visited = set()\n",
    "    queue = [start_node]\n",
    "\n",
    "    while queue and len(visited) < num_nodes:\n",
    "        node = queue.pop(0)\n",
    "        if node not in visited:\n",
    "            visited.add(node)\n",
    "            neighbors = set(graph.neighbors(node)) - visited\n",
    "            queue.extend(neighbors)\n",
    "\n",
    "    return list(visited)\n",
    "\n",
    "random.seed(22)\n",
    "start_node = random.choice(list(G_knn.nodes()))\n",
    "sample_nodes = bfs_sample(G_knn, start_node, 200)\n",
    "\n",
    "subG = G_knn.subgraph(sample_nodes)\n",
    "\n",
    "def color_map(graph):\n",
    "    return ['#636EFA' if graph.nodes[n].get('label', 0.0) == 0.0 else '#e8e337' for n in graph.nodes()] #add features and run again else it wont work\n",
    "\n",
    "node_colors = color_map(subG)\n",
    "plt.figure(figsize=(12, 12))\n",
    "pos = nx.kamada_kawai_layout(subG) # or spectral_layout, spring_layout, circular_layout, shell_layout\n",
    "nx.draw(subG, pos, with_labels=False, node_size=150, node_color=node_colors)\n",
    "\n",
    "blue_patch = mpatches.Patch(color='#636EFA', label='Negative (0)')\n",
    "yellow_patch = mpatches.Patch(color='#e8e337', label='Positive (1)')\n",
    "plt.legend(handles=[blue_patch, yellow_patch])\n",
    "plt.title(\"Patient similarity: subgraph visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretability: visualizing node neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_map(graph, highlight_node=None):\n",
    "    colors = []\n",
    "    for n in graph.nodes():\n",
    "        if n == highlight_node:\n",
    "            colors.append('#FF5733')  \n",
    "        else:\n",
    "            colors.append('#636EFA' if graph.nodes[n].get('label', 0.0) == 0.0 else '#e8e337')\n",
    "    return colors\n",
    "\n",
    "def show_node_neighborhood(graph, patient_id):\n",
    "    if patient_id not in graph:\n",
    "        print(f\"Node {patient_id} not found in the graph.\")\n",
    "        return\n",
    "    \n",
    "    immediate_neighbors = list(graph.neighbors(patient_id))\n",
    "    neighbors_of_neighbors = [n for neighbor in immediate_neighbors for n in graph.neighbors(neighbor)]\n",
    "    neighbors_of_neighbors = list(set(neighbors_of_neighbors + immediate_neighbors + [patient_id]))\n",
    "\n",
    "    neighborhood_subG = graph.subgraph(neighbors_of_neighbors)\n",
    "    \n",
    "    node_colors = color_map(neighborhood_subG, highlight_node=patient_id)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos = nx.shell_layout(neighborhood_subG)\n",
    "\n",
    "    nx.draw(neighborhood_subG, pos, with_labels=True, node_size=300, node_color=node_colors, edge_color='#BBBBBB')\n",
    "    \n",
    "    #target node\n",
    "    node_color = '#636EFA' if graph.nodes[patient_id].get('label', 0.0) == 0.0 else '#e8e337'\n",
    "    nx.draw_networkx_nodes(neighborhood_subG, pos, nodelist=[patient_id], node_size=1000, \n",
    "                           node_color=node_color, edgecolors='red', linewidths=5)\n",
    "\n",
    "    blue_patch = mpatches.Patch(color='#636EFA', label='Negative (0)')\n",
    "    yellow_patch = mpatches.Patch(color='#e8e337', label='Positive (1)')\n",
    "    highlight_patch = mpatches.Patch(color='red', label='Target node')\n",
    "    plt.legend(handles=[blue_patch, yellow_patch], title=\"True label\")\n",
    "\n",
    "    # dashed circle around immediate neighbors\n",
    "    for neighbor in immediate_neighbors:\n",
    "        circle = plt.Circle(pos[neighbor], radius=0.1, color='gray', fill=False, linestyle='dashed')\n",
    "        plt.gca().add_patch(circle)\n",
    "    \n",
    "    plt.title(f\"Neighborhood of FP patient, ID = {patient_id}\")\n",
    "    plt.show()\n",
    "\n",
    "patient_id = 11745\n",
    "show_node_neighborhood(G_knn, patient_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding node features\n",
    "For each node, let's add feature vectors - the same feature vector we used to build the graph. With this, we will then run the GNN for HF prediction in a transductive setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(label_df, graph):\n",
    "    logging.info('Adding node features...')\n",
    "\n",
    "    for _, row in tqdm(label_df.iterrows(), total=label_df.shape[0], desc='Processing features'):\n",
    "        patient_id = row['patient_id']\n",
    "\n",
    "        if graph.has_node(patient_id):\n",
    "            # create a feature vector excluding the 'patient_id' and 'label' columns\n",
    "            feature_vector = row.drop(['patient_id', 'label'])\n",
    "            graph.nodes[patient_id]['features'] = feature_vector\n",
    "\n",
    "            # add label\n",
    "            graph.nodes[patient_id]['label'] = row['label']\n",
    "        else:\n",
    "            logging.warning(f\"Warning: patient_id {patient_id} does not exist in the graph.\")\n",
    "\n",
    "    logging.info('Node features added.')\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_patient_ids = set(G_knn.nodes())\n",
    "df_patient_ids = set(patient_data['patient_id'])\n",
    "\n",
    "# find the patient IDs that are in label_df but not in the graph\n",
    "missing_in_graph = df_patient_ids - graph_patient_ids\n",
    "\n",
    "# find the patient IDs that are in the graph but not in label_df\n",
    "extra_in_graph = graph_patient_ids - df_patient_ids\n",
    "\n",
    "print(\"Missing in graph:\", len(missing_in_graph))\n",
    "print(\"Extra in graph:\", len(extra_in_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ablation/feature studies - replace node features\n",
    "patient_data_diag = pd.read_csv(r\"PATH/patient_emb_cols_ablation-diag.csv\")\n",
    "patient_data_proc = pd.read_csv(r\"PATH/patient_emb_cols_ablation-proc.csv\")\n",
    "patient_data_pres = pd.read_csv(r\"PATH/patient_emb_cols_ablation-pres.csv\")\n",
    "\n",
    "patient_data_demo = pd.read_csv(r\"PATH/patient_emb_cols_ablation-demo.csv\")\n",
    "\n",
    "patient_data_without_diag = pd.read_csv(r\"PATH/patient_emb_cols_ablation-without_diag.csv\")\n",
    "patient_data_without_proc = pd.read_csv(r\"PATH/patient_emb_cols_ablation-without_proc.csv\")\n",
    "patient_data_without_pres = pd.read_csv(r\"PATH/patient_emb_cols_ablation-without_pres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding node features\n",
    "G_knn = add_features(patient_data, G_knn) #patient_data_merged for use with other onehot features \n",
    "\n",
    "# for ablation: patient_data_diag, patient_data_proc, patient_data_pres, patient_data_demo (demographics) (just change in here: ADD_FEATURES fn)!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the graph with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check positive and negative labeled nodes\n",
    "positive_nodes = [node for node, data in G_knn.nodes(data=True) if data['label'] == 1]\n",
    "negative_nodes = [node for node, data in G_knn.nodes(data=True) if data['label'] == 0]\n",
    "\n",
    "print(f\"No. positive HF patients: {len(positive_nodes)}\")\n",
    "print(f\"No. negative HF patients: {len(negative_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a node's attributes\n",
    "def inspect_node(node):\n",
    "    data = G_knn.nodes[node]\n",
    "    neighbors = list(G_knn.neighbors(node))\n",
    "\n",
    "    edge_weights = [G_knn[node][neighbor]['weight'] for neighbor in neighbors]\n",
    "    \n",
    "    return {\n",
    "        \"Node/Patient ID\": node,\n",
    "        \"Label\": data['label'],\n",
    "        \"Features\": data['features'],\n",
    "        \"Neighbors\": neighbors,\n",
    "        \"Edge weights\": edge_weights,\n",
    "        \"Degrees\": len(neighbors)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating random positive and negative samples\n",
    "sample_pos_node = positive_nodes[0]\n",
    "sample_neg_node = negative_nodes[0]\n",
    "\n",
    "inspect_node(sample_pos_node), inspect_node(sample_neg_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge weights distribution\n",
    "edge_weights = [data['weight'] for _, _, data in G_knn.edges(data=True)]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(edge_weights, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.title(\"Distribution of edge weights\")\n",
    "plt.xlabel(\"Edge weight (similarity score)\")\n",
    "plt.ylabel(\"No. of edges\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any isolated nodes\n",
    "isolated_nodes = [node for node, degree in G_knn.degree() if degree == 0]\n",
    "print(f\"No. isolated nodes: {len(isolated_nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexing and saving the final graph\n",
    "We have to reindex the final graph so we won't have any problems with the GNN processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_with_patient_id(G):\n",
    "    #reindexes the nodes of the graph G from 0 to n-1, retains original patient_id as an attribute, transfers all node and edge attributes\n",
    "    #G = graph to be reindexed\n",
    "    node_mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "    \n",
    "    G_reindexed = nx.Graph()\n",
    "    \n",
    "    # reindex nodes and transfer node attributes\n",
    "    for node, data in G.nodes(data=True):\n",
    "        G_reindexed.add_node(node_mapping[node], patient_id=node, **data)\n",
    "    \n",
    "    # reindex edges and transfer edge attributes\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        G_reindexed.add_edge(node_mapping[u], node_mapping[v], **data)\n",
    "    \n",
    "    return G_reindexed\n",
    "\n",
    "def check_patient_id_consistency(original_graph, reindexed_graph):\n",
    "    #check if nodes in the reindexed graph have the correct patient_id info\n",
    "    # create a mapping from reindexed nodes to their original patient_id\n",
    "    reindexed_to_patient_id = nx.get_node_attributes(reindexed_graph, 'patient_id')\n",
    "    \n",
    "    # for each node in the original graph, check if its corresponding node in the reindexed graph \n",
    "    # has the correct patient_id\n",
    "    for original_node in original_graph.nodes():\n",
    "        reindexed_node = list(original_graph.nodes()).index(original_node)\n",
    "        if reindexed_to_patient_id[reindexed_node] != original_node:\n",
    "            print(f\"Mismatch found: Node {reindexed_node} in reindexed graph should have patient_id {original_node}, but has {reindexed_to_patient_id[reindexed_node]}\")\n",
    "            return False\n",
    "\n",
    "    print(\"All nodes in the reindexed graph have the correct patient_id.\")\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_knn_reindexed = reindex_with_patient_id(G_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_knn_reindexed.number_of_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_consistent = check_patient_id_consistency(G_knn, G_knn_reindexed)\n",
    "print(f\"Consistency check result: {is_consistent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_edges = {(min(u, v), max(u, v)) for u, v in G_knn_reindexed.edges()}\n",
    "len(canonical_edges), G_knn_reindexed.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving final graph, with features and reindexed\n",
    "graph_path = r\"PATH/medicalcodegraph.pkl\" \n",
    "\n",
    "if os.path.exists(graph_path):\n",
    "    with open(graph_path, 'rb') as f:\n",
    "        G_knn_reindexed = pkl.load(f)\n",
    "else:\n",
    "\n",
    "    with open(graph_path, 'wb') as f:\n",
    "        pkl.dump(G_knn_reindexed, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sweep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
